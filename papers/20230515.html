<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>ML 論文メモ</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>ML 論文メモ</h1>
        <nav>
            <ul>
                <li><a href="../index.html">ホーム</a></li>
            </ul>
        </nav>
    </header>
    <main>
        <br>
        <section id="paper-info">
            <h2>論文情報</h2>
            <ul>
                <li><strong>タイトル ： </strong>Exact natural gradient in deep linear networks and its application to the nonlinear case</li>
                <li><strong>学会 ： </strong>neurips</li>
                <li><strong>出版年 ： </strong>2018</li>
                <li><strong>論文リンク ： </strong><a href="https://proceedings.neurips.cc/paper/2018/hash/7f018eb7b301a66658931cb8a93fd6e8-Abstract.html">https://proceedings.neurips.cc/paper/2018/hash/7f018eb7b301a66658931cb8a93fd6e8-Abstract.html</a></li>
            </ul>
        </section>
        <section id="paper-summary">
            <h2>論文メモ</h2>
            <ul>
                <li>線形のニューラルネットワークにおいてNatural Gradient Descent(自然勾配法)の挙動を時間追跡している論文．ブロック対角近似の正当化にもなっている．</li>
                <li>Natural Gradient Descentは最小二乗解に指数的に収束する一方，Natural Gradient Descent以外のPreconditioned Gradient Descentは指数的な収束が不可能であることを示している．</li>
                <li></li>
            </ul>
        </section>
    </main>
    <footer>
        <p>&copy; 2023 ML論文メモ</p>
    </footer>
</body>
</html>
