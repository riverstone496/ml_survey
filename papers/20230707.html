<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>ML 論文メモ</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>ML 論文メモ</h1>
        <nav>
            <ul>
                <li><a href="../index.html">ホーム</a></li>
            </ul>
        </nav>
    </header>
    <main>
        <br>
        <section id="paper-info">
            <h2>論文情報</h2>
            <ul>
                <li><strong>タイトル ： </strong>On the interplay between noise and curvature and its effect on optimization and generalization
                </li>
                <li><strong>著者 ： </strong>Valentin Thomas, Fabian Pedregosa, Bart van Merriënboer, Pierre-Antoine Mangazol, Yoshua Bengio, Nicolas Le Roux
                </li>
                <li><strong>学会 ： </strong>AISTATS</li>
                <li><strong>出版年 ： </strong>2020</li>
                <li><strong>論文リンク ： </strong><a href="https://arxiv.org/abs/1906.07774">https://arxiv.org/abs/1906.07774</a></li>
            </ul>
        </section>
        <section id="paper-abstract">
            <h2>Abstract</h2>
            <ul>
                確率的な方法を使用して期待損失を最小化するspeedは,2つの特性に依存します: 損失の曲率と勾配の分散です.多くの先行研究がこれらの特性のいずれかに焦点を当てている一方で,私たちはそれらの相互作用が最適化のspeedにどのように影響するかを探求します.さらに,最終的な目標は良好な一般化性能であるため,曲率とノイズの両方が一般化ギャップを適切に推定するためにどれほど関連しているかを明確にします.一部の既存の研究の制約がこれらの行列間の混同に起因していることに気付き,私たちはFisher行列,ヘッシアン,および勾配の共分散行列との間の区別も明確にします.
            </ul>
        </section>
        <section id="paper-summary">
            <h2>論文メモ</h2>
            <ul>
                <li>最適化手法の収束に関わるlossのcurvatureとnoiseの関係を分析．</li>
                <li>深層学習の汎化指標としてもTICは有効であることを示す．</li>
            </ul>
        </section>
    </main>
    <footer>
        <p>&copy; 2023 ML論文メモ</p>
    </footer>
</body>
</html>
