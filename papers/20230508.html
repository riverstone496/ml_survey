<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>ML 論文メモ</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>ML 論文メモ</h1>
        <nav>
            <ul>
                <li><a href="../index.html">ホーム</a></li>
            </ul>
        </nav>
    </header>
    <main>
        <br>
        <section id="paper-info">
            <h2>論文情報</h2>
            <ul>
                <li><strong>タイトル ： </strong>The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers</li>
                <li><strong>著者 ： </strong>Preetum Nakkiran, Behnam Neyshabur, Hanie Sedghi</li>
                <li><strong>学会 ： </strong>ICLR</li>
                <li><strong>出版年 ： </strong>2021</li>
                <li><strong>論文リンク ： </strong><a href="https://arxiv.org/abs/2010.08127">https://arxiv.org/abs/2010.08127</a></li>
            </ul>
        </section>
        <section id="paper-abstract">
            <h2>Abstract</h2>
            <ul>
                私たちは,ディープラーニングにおける汎化についての推論のための新しいフレームワークを提案します.中心的な考えは,実世界での最適化手法が経験的な損失に対して確率的な勾配ステップを取るのに対し,理想的な世界では,最適化手法が母集団の損失に対してステップを取るというものです.これにより,テストエラーを次のように別の要素に分解することができます: (1) 理想的な世界でのテストエラー (2)理想的な世界と実世界の間のギャップ.ギャップ(2)が普遍的に小さい場合,オフライン学習における汎化の問題は,オンライン学習における最適化の問題に還元されます.次に,実際のディープラーニングの設定,特に教師あり画像分類において,世界間のこのギャップが小さくなる可能性があるという実証的な証拠を示します.例えば,実世界の画像分布において,CNNはMLPよりもよく汎化しますが,これは"理由として"理想的な世界での母集団の損失に対してより速く最適化するからです.これは,私たちのフレームワークがディープラーニングにおける汎化を理解するための有用なツールであることを示唆しており,この分野での今後の研究の基盤を築くものです.
            </ul>
        </section>
        <section id="paper-summary">
            <h2>論文メモ</h2>
            <ul>
                <li>有限データセットにおける汎化損失は，無限にデータがあるオンライン学習の損失と関係があることを示す論文．この関係はモデルが学習データセットに対して完全にfitするまでの間成立する．</li>
                <li>従来は汎化損失を学習損失と汎化ギャップの和として分解することが多かった．この論文では，汎化損失をオンライン学習における損失とそれ以外（Bootstrap Error）に分解．training lossが0になるまでの間はこのBootstrap Errorは0に近いことを示す．これによって，汎化損失がオンライン損失によってモデル化されることを経験的に正当化している．</li>
            </ul>
        </section>
    </main>
    <footer>
        <p>&copy; 2023 ML論文メモ</p>
    </footer>
</body>
</html>
